{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network dimensionality and universality of rules\n",
    "\n",
    "## For every considered model, vary (1) number and (2) width of layers. Otherwise same as 'comparing'.\n",
    "\n",
    "Created by Basile Van Hoorick, Fall 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FF_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(hyperparams, all_stats):\n",
    "\n",
    "    num_configs = len(hyperparams)\n",
    "    test_accs_up = []\n",
    "    test_accs_down = []\n",
    "    speeds_down = []\n",
    "\n",
    "    for i in range(num_configs):\n",
    "\n",
    "        universal, l, w, cap = hyperparams[i]\n",
    "    #     print('Universal:', universal)\n",
    "    #     print('Number hidden layers:', l)\n",
    "    #     print('Hidden layer width:', w)\n",
    "    #     print('Cap:', cap)\n",
    "\n",
    "        stats_up, stats_down = all_stats[i]\n",
    "        stats_up = convert_multi_stats_uncertainty(stats_up)\n",
    "        stats_down = convert_multi_stats_uncertainty(stats_down)\n",
    "        test_acc_up = stats_up[2][-1]\n",
    "        test_acc_down = stats_down[2][-1]\n",
    "        speed_down = np.mean(stats_down[2]) / test_acc_down\n",
    "\n",
    "    #     print(f'Final upstream test accuracy: {test_acc_up*100:.2f}%')\n",
    "    #     print(f'Final downstream test accuracy: {test_acc_down*100:.2f}%')\n",
    "    #     print(f'Downstream speed of convergence: {speed_down*100:.2f}%')\n",
    "    #     print()\n",
    "\n",
    "        test_accs_up.append(test_acc_up)\n",
    "        test_accs_down.append(test_acc_down)\n",
    "        speeds_down.append(speed_down)\n",
    "\n",
    "    test_accs_up = np.array(test_accs_up).reshape((2, 3, 3))\n",
    "    test_accs_down = np.array(test_accs_down).reshape((2, 3, 3))\n",
    "    speeds_down = np.array(speeds_down).reshape((2, 3, 3))\n",
    "    metrics = np.multiply(test_accs_up, test_accs_down, speeds_down)\n",
    "\n",
    "    print('Upstream accuracy:')\n",
    "    print(test_accs_up)\n",
    "    print('Downstream accuracy:')\n",
    "    print(test_accs_down)\n",
    "    print('Downstream speed:')\n",
    "    print(speeds_down)\n",
    "    print('Product:')\n",
    "    print(metrics)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Henceforth, we use GD directly on inputs but use plasticity rules in the output and hidden layers.\n",
    "opts = Options(gd_input=True,\n",
    "               use_graph_rule=True,\n",
    "               gd_graph_rule=True,\n",
    "               use_output_rule=True,\n",
    "               gd_output_rule=True,\n",
    "               gd_output=False)\n",
    "scheme = UpdateScheme(cross_entropy_loss=True,\n",
    "                      mse_loss=False,\n",
    "                      update_misclassified_only=False,\n",
    "                      update_all_edges=True)\n",
    "\n",
    "# Feed-forward brain config.\n",
    "n_up = 16  # Input layer size for meta-learning.\n",
    "n_down = 16  # Input layer size for desired task training.\n",
    "n = 16  # Input layer size.\n",
    "m = 2  # Output layer size.\n",
    "p = 0.5  # Connectivity probability.\n",
    "\n",
    "# Training config.\n",
    "num_runs = 5\n",
    "num_rule_epochs = 50\n",
    "num_epochs_upstream = 1\n",
    "num_epochs_downstream = 1\n",
    "dataset = 'halfspace'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 16\n",
      "Cap: 8\n",
      "==== Interpretation: Pre and Post ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:55<00:00,  2.31s/it]\n",
      "  4%|▎         | 54/1500 [00:00<00:02, 496.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3789\n",
      "Last train accuracy: 0.9347\n",
      "Last test accuracy: 0.9120\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4940\n",
      "INITIAL test accuracy: 0.4600\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 429.37it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6304\n",
      "Last train accuracy: 0.6707\n",
      "Last test accuracy: 0.6820\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:49<00:00,  2.18s/it]\n",
      "  2%|▏         | 29/1500 [00:00<00:05, 284.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4887\n",
      "Last test accuracy: 0.4920\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4987\n",
      "INITIAL test accuracy: 0.4860\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 404.29it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4987\n",
      "Last test accuracy: 0.4860\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:48<00:00,  2.18s/it]\n",
      "  3%|▎         | 49/1500 [00:00<00:03, 483.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5093\n",
      "Last test accuracy: 0.5020\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5227\n",
      "INITIAL test accuracy: 0.5360\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 443.10it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5227\n",
      "Last test accuracy: 0.5360\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:52<00:00,  2.25s/it]\n",
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3656\n",
      "Last train accuracy: 0.9647\n",
      "Last test accuracy: 0.9380\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5047\n",
      "INITIAL test accuracy: 0.5280\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 415.02it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7123\n",
      "Last train accuracy: 0.5933\n",
      "Last test accuracy: 0.6040\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:56<00:00,  2.34s/it]\n",
      "  3%|▎         | 49/1500 [00:00<00:03, 482.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3676\n",
      "Last train accuracy: 0.9667\n",
      "Last test accuracy: 0.9400\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5020\n",
      "INITIAL test accuracy: 0.4880\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 381.14it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7349\n",
      "Last train accuracy: 0.6007\n",
      "Last test accuracy: 0.5900\n",
      "\n",
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 32\n",
      "Cap: 16\n",
      "==== Interpretation: Pre and Post ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:02<00:00,  2.44s/it]\n",
      "  3%|▎         | 45/1500 [00:00<00:03, 441.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3538\n",
      "Last train accuracy: 0.9693\n",
      "Last test accuracy: 0.9420\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4887\n",
      "INITIAL test accuracy: 0.4800\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 314.78it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7169\n",
      "Last train accuracy: 0.5813\n",
      "Last test accuracy: 0.5940\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.42s/it]\n",
      "  3%|▎         | 47/1500 [00:00<00:03, 465.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3564\n",
      "Last train accuracy: 0.9620\n",
      "Last test accuracy: 0.9280\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5007\n",
      "INITIAL test accuracy: 0.4560\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 402.46it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6470\n",
      "Last train accuracy: 0.6533\n",
      "Last test accuracy: 0.6320\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:59<00:00,  2.38s/it]\n",
      "  3%|▎         | 46/1500 [00:00<00:03, 457.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3570\n",
      "Last train accuracy: 0.9707\n",
      "Last test accuracy: 0.9420\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4780\n",
      "INITIAL test accuracy: 0.5180\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 394.38it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7069\n",
      "Last train accuracy: 0.6307\n",
      "Last test accuracy: 0.6280\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.42s/it]\n",
      "  3%|▎         | 47/1500 [00:00<00:03, 464.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4820\n",
      "Last test accuracy: 0.5180\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5000\n",
      "INITIAL test accuracy: 0.5080\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 391.62it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5000\n",
      "Last test accuracy: 0.5080\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:55<00:00,  2.31s/it]\n",
      "  3%|▎         | 46/1500 [00:00<00:03, 459.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3597\n",
      "Last train accuracy: 0.9653\n",
      "Last test accuracy: 0.9380\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4980\n",
      "INITIAL test accuracy: 0.4720\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 416.49it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6788\n",
      "Last train accuracy: 0.6500\n",
      "Last test accuracy: 0.6640\n",
      "\n",
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 64\n",
      "Cap: 32\n",
      "==== Interpretation: Pre and Post ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.69s/it]\n",
      "  3%|▎         | 42/1500 [00:00<00:03, 417.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3500\n",
      "Last train accuracy: 0.9673\n",
      "Last test accuracy: 0.9200\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5107\n",
      "INITIAL test accuracy: 0.4760\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 342.52it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6818\n",
      "Last train accuracy: 0.6360\n",
      "Last test accuracy: 0.6360\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:13<00:00,  2.66s/it]\n",
      "  2%|▏         | 32/1500 [00:00<00:04, 305.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4987\n",
      "Last test accuracy: 0.5560\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4973\n",
      "INITIAL test accuracy: 0.4500\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 388.27it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.3933\n",
      "Last test accuracy: 0.3920\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:21<00:00,  2.84s/it]\n",
      "  2%|▏         | 25/1500 [00:00<00:05, 246.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6913\n",
      "Last train accuracy: 0.5040\n",
      "Last test accuracy: 0.5560\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4933\n",
      "INITIAL test accuracy: 0.5120\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 337.94it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.8329\n",
      "Last train accuracy: 0.5067\n",
      "Last test accuracy: 0.4880\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:14<00:00,  2.69s/it]\n",
      "  3%|▎         | 42/1500 [00:00<00:03, 413.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3496\n",
      "Last train accuracy: 0.9607\n",
      "Last test accuracy: 0.9380\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4940\n",
      "INITIAL test accuracy: 0.5040\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 357.72it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6388\n",
      "Last train accuracy: 0.6907\n",
      "Last test accuracy: 0.6700\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:53<00:25,  2.88s/it]"
     ]
    }
   ],
   "source": [
    "hyperparams_prepost = []\n",
    "all_stats_prepost = []\n",
    "\n",
    "for universal in [False, True]:  # Specialized rules or not?\n",
    "    \n",
    "    for l in [2, 3, 4]:  # Number of hidden layers.\n",
    "        \n",
    "        for w in [16, 32, 64]:  # Width of hidden layers.\n",
    "            \n",
    "            cap = w // 2  # Number of nodes firing per layer.\n",
    "            print('Universal:', universal)\n",
    "            print('Number hidden layers:', l)\n",
    "            print('Hidden layer width:', w)\n",
    "            print('Cap:', cap)\n",
    "            hyperparams_prepost.append((universal, l, w, cap))\n",
    "            \n",
    "            brain_prepost_fact = lambda: FFLocalNet(\n",
    "                n, m, l, w, p, cap,\n",
    "                hl_rules=TableRule_PrePost() if universal else [TableRule_PrePost()] * (l-1),\n",
    "                output_rule=TableRule_PrePost(), options=opts, update_scheme=scheme)\n",
    "            \n",
    "            print('==== Interpretation: Pre and Post ====')\n",
    "            cur_stats = evaluate_brain(\n",
    "                brain_prepost_fact, n, dataset=dataset,\n",
    "                num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "            all_stats_prepost.append(cur_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upstream accuracy:\n",
      "[[[0.7728 0.8699 0.7777]\n",
      "  [0.76   0.7613 0.7577]\n",
      "  [0.5852 0.7457 0.6449]]\n",
      "\n",
      " [[0.8688 0.6981 0.8733]\n",
      "  [0.7563 0.8547 0.7613]\n",
      "  [0.5863 0.5237 0.5852]]]\n",
      "Downstream accuracy:\n",
      "[[[0.5772 0.6031 0.578 ]\n",
      "  [0.5515 0.5484 0.5841]\n",
      "  [0.5016 0.5348 0.5416]]\n",
      "\n",
      " [[0.5955 0.5597 0.6343]\n",
      "  [0.5428 0.5861 0.5472]\n",
      "  [0.5248 0.5003 0.5561]]]\n",
      "Downstream speed:\n",
      "[[[0.4461 0.5246 0.4495]\n",
      "  [0.4191 0.4175 0.4426]\n",
      "  [0.2935 0.3988 0.3493]]\n",
      "\n",
      " [[0.5173 0.3908 0.5539]\n",
      "  [0.4105 0.5009 0.4166]\n",
      "  [0.3077 0.262  0.3254]]]\n",
      "Product:\n",
      "[[[0.4461 0.5246 0.4495]\n",
      "  [0.4191 0.4175 0.4426]\n",
      "  [0.2935 0.3988 0.3493]]\n",
      "\n",
      " [[0.5173 0.3908 0.5539]\n",
      "  [0.4105 0.5009 0.4166]\n",
      "  [0.3077 0.262  0.3254]]]\n"
     ]
    }
   ],
   "source": [
    "metrics_prepost = get_metrics(hyperparams_prepost, all_stats_prepost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three best configs:\n",
    "\n",
    "* XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePostCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 16\n",
      "Cap: 8\n",
      "==== Interpretation: PrePostCount ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:45<00:00,  2.12s/it]\n",
      "  3%|▎         | 45/1500 [00:00<00:03, 441.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3909\n",
      "Last train accuracy: 0.9467\n",
      "Last test accuracy: 0.9360\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4973\n",
      "INITIAL test accuracy: 0.5180\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 491.00it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6596\n",
      "Last train accuracy: 0.6420\n",
      "Last test accuracy: 0.6260\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:52<00:00,  2.26s/it]\n",
      "  3%|▎         | 43/1500 [00:00<00:03, 426.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3795\n",
      "Last train accuracy: 0.9687\n",
      "Last test accuracy: 0.9440\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5300\n",
      "INITIAL test accuracy: 0.4980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 492.96it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6648\n",
      "Last train accuracy: 0.6360\n",
      "Last test accuracy: 0.6320\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:43<00:00,  2.07s/it]\n",
      "  4%|▎         | 56/1500 [00:00<00:02, 551.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5207\n",
      "Last test accuracy: 0.5000\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4920\n",
      "INITIAL test accuracy: 0.5080\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:02<00:00, 512.97it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4920\n",
      "Last test accuracy: 0.5080\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:34<00:00,  1.89s/it]\n",
      "  3%|▎         | 44/1500 [00:00<00:03, 436.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4933\n",
      "Last test accuracy: 0.5400\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4860\n",
      "INITIAL test accuracy: 0.5220\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:02<00:00, 501.01it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4860\n",
      "Last test accuracy: 0.5220\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:47<00:00,  2.15s/it]\n",
      "  3%|▎         | 44/1500 [00:00<00:03, 435.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4907\n",
      "Last test accuracy: 0.4700\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4933\n",
      "INITIAL test accuracy: 0.5200\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:02<00:00, 501.76it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5067\n",
      "Last test accuracy: 0.4800\n",
      "\n",
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 32\n",
      "Cap: 16\n",
      "==== Interpretation: PrePostCount ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:59<00:00,  2.39s/it]\n",
      "  3%|▎         | 43/1500 [00:00<00:03, 420.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5100\n",
      "Last test accuracy: 0.4880\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4953\n",
      "INITIAL test accuracy: 0.4940\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 474.28it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.6693\n",
      "Last test accuracy: 0.6620\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:50<00:00,  2.22s/it]\n",
      "  3%|▎         | 42/1500 [00:00<00:03, 418.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3663\n",
      "Last train accuracy: 0.9713\n",
      "Last test accuracy: 0.9500\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4933\n",
      "INITIAL test accuracy: 0.4820\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 486.50it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6663\n",
      "Last train accuracy: 0.6327\n",
      "Last test accuracy: 0.6360\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:46<00:00,  2.13s/it]\n",
      "  3%|▎         | 40/1500 [00:00<00:03, 393.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3681\n",
      "Last train accuracy: 0.9480\n",
      "Last test accuracy: 0.9300\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5213\n",
      "INITIAL test accuracy: 0.4860\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 479.82it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6605\n",
      "Last train accuracy: 0.6373\n",
      "Last test accuracy: 0.6140\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:24<00:00,  2.88s/it]\n",
      "  3%|▎         | 41/1500 [00:00<00:03, 408.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3658\n",
      "Last train accuracy: 0.9720\n",
      "Last test accuracy: 0.9360\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4940\n",
      "INITIAL test accuracy: 0.5200\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 367.77it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6276\n",
      "Last train accuracy: 0.6720\n",
      "Last test accuracy: 0.6740\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:23<00:00,  2.87s/it]\n",
      "  3%|▎         | 43/1500 [00:00<00:03, 420.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5067\n",
      "Last test accuracy: 0.5360\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5227\n",
      "INITIAL test accuracy: 0.4960\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 370.39it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5227\n",
      "Last test accuracy: 0.4960\n",
      "\n",
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 64\n",
      "Cap: 32\n",
      "==== Interpretation: PrePostCount ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:44<00:00,  3.29s/it]\n",
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3487\n",
      "Last train accuracy: 0.9767\n",
      "Last test accuracy: 0.9360\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5047\n",
      "INITIAL test accuracy: 0.4780\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 339.21it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.5401\n",
      "Last train accuracy: 0.7687\n",
      "Last test accuracy: 0.7460\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:46<00:00,  3.34s/it]\n",
      "  2%|▏         | 34/1500 [00:00<00:04, 339.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3596\n",
      "Last train accuracy: 0.9740\n",
      "Last test accuracy: 0.9380\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4967\n",
      "INITIAL test accuracy: 0.5120\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 344.83it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7115\n",
      "Last train accuracy: 0.6133\n",
      "Last test accuracy: 0.6240\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:45<00:00,  3.32s/it]\n",
      "  2%|▏         | 27/1500 [00:00<00:05, 256.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3585\n",
      "Last train accuracy: 0.9773\n",
      "Last test accuracy: 0.9420\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4780\n",
      "INITIAL test accuracy: 0.4600\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 762/1500 [00:02<00:02, 320.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e3d2e6700702>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mbrain_prepostcount_fact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rule_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rule_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mall_stats_prepostcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-398466071b4c>\u001b[0m in \u001b[0;36mevaluate_brain\u001b[0;34m(brain_fact, n, dataset, num_runs, num_rule_epochs, num_epochs_upstream, num_epochs_downstream)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvanilla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             stats_interval=500, disable_backprop=True)\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Save this run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/train.py\u001b[0m in \u001b[0;36mtrain_downstream\u001b[0;34m(X, y, model, num_epochs, batch_size, vanilla, learn_rate, X_test, y_test, verbose, stats_interval, disable_backprop)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;31m# Update selected weights using rules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinue_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;31m# Update remaining weights using backprop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/FFLocalNet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels, epochs, batch, continue_)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;31m# Update the weights using the recorded activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Generate outputs using final weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/FFLocalNet.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, probs, label)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# Determine the plasticity beta values to use for each entry in the weight matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mrule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_rules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0mbetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_betas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;31m# Use beta=0 (no update) for any synapse that doesn't exist according to the connectivity graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/FFLocalPlasticityRules/TablePlasticityRule.py\u001b[0m in \u001b[0;36mhidden_layer_betas\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Convert these dimension indexes into scalar indexes into the flattened hidden-layer rule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mrule_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel_multi_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Return the corresponding array of beta values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mravel_multi_index\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams_prepostcount = []\n",
    "all_stats_prepostcount = []\n",
    "\n",
    "for universal in [False, True]:  # Specialized rules or not?\n",
    "    \n",
    "    for l in [2, 3, 4]:  # Number of hidden layers.\n",
    "        \n",
    "        for w in [16, 32, 64]:  # Width of hidden layers.\n",
    "            \n",
    "            cap = w // 2  # Number of nodes firing per layer.\n",
    "            print('Universal:', universal)\n",
    "            print('Number hidden layers:', l)\n",
    "            print('Hidden layer width:', w)\n",
    "            print('Cap:', cap)\n",
    "            hyperparams_prepostcount.append((universal, l, w, cap))\n",
    "            \n",
    "            brain_prepostcount_fact = lambda: FFLocalNet(\n",
    "                n, m, l, w, p, cap,\n",
    "                hl_rules=TableRule_PrePostCount() if universal else [TableRule_PrePostCount()] * (l-1),\n",
    "                output_rule=TableRule_PrePostCount(), options=opts, update_scheme=scheme)\n",
    "            \n",
    "            print('==== Interpretation: PrePostCount ====')\n",
    "            cur_stats = evaluate_brain(\n",
    "                brain_prepostcount_fact, n, dataset=dataset,\n",
    "                num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "            all_stats_prepostcount.append(cur_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_prepostcount = get_metrics(hyperparams_prepostcount, all_stats_prepostcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePostPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_prepostpercent = []\n",
    "all_stats_prepostpercent = []\n",
    "\n",
    "for universal in [False, True]:  # Specialized rules or not?\n",
    "    \n",
    "    for l in [2, 3, 4]:  # Number of hidden layers.\n",
    "        \n",
    "        for w in [16, 32, 64]:  # Width of hidden layers.\n",
    "            \n",
    "            cap = w // 2  # Number of nodes firing per layer.\n",
    "            print('Universal:', universal)\n",
    "            print('Number hidden layers:', l)\n",
    "            print('Hidden layer width:', w)\n",
    "            print('Cap:', cap)\n",
    "            hyperparams_prepostpercent.append((universal, l, w, cap))\n",
    "            \n",
    "            brain_prepostpercent_fact = lambda: FFLocalNet(\n",
    "                n, m, l, w, p, cap,\n",
    "                hl_rules=TableRule_PrePostPercent() if universal else [TableRule_PrePostPercent()] * (l-1),\n",
    "                output_rule=TableRule_PrePostPercent(), options=opts, update_scheme=scheme)\n",
    "            \n",
    "            print('==== Interpretation: PrePostPercent ====')\n",
    "            cur_stats = evaluate_brain(\n",
    "                brain_prepostpercent_fact, n, dataset=dataset,\n",
    "                num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "            all_stats_prepostpercent.append(cur_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyperparams_prepostpercent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1e8fd6a2eedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmetrics_prepostpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams_prepostpercent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_stats_prepostpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hyperparams_prepostpercent' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_prepostpercent = get_metrics(hyperparams_prepostpercent, all_stats_prepostpercent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
