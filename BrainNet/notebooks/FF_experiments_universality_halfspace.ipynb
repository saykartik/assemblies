{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network dimensionality and universality of rules\n",
    "\n",
    "## For every considered model, vary (1) number and (2) width of layers. Otherwise same as 'comparing'.\n",
    "\n",
    "Created by Basile Van Hoorick, Fall 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FF_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(hyperparams, all_stats):\n",
    "\n",
    "    num_configs = len(hyperparams)\n",
    "    test_accs_up = []\n",
    "    test_accs_down = []\n",
    "    speeds_down = []\n",
    "\n",
    "    for i in range(num_configs):\n",
    "\n",
    "        universal, l, w, cap = hyperparams[i]\n",
    "    #     print('Universal:', universal)\n",
    "    #     print('Number hidden layers:', l)\n",
    "    #     print('Hidden layer width:', w)\n",
    "    #     print('Cap:', cap)\n",
    "\n",
    "        stats_up, stats_down = all_stats[i]\n",
    "        stats_up = convert_multi_stats_uncertainty(stats_up)\n",
    "        stats_down = convert_multi_stats_uncertainty(stats_down)\n",
    "        test_acc_up = stats_up[2][-1]\n",
    "        test_acc_down = stats_down[2][-1]\n",
    "        speed_down = np.mean(stats_down[2]) / test_acc_down\n",
    "\n",
    "    #     print(f'Final upstream test accuracy: {test_acc_up*100:.2f}%')\n",
    "    #     print(f'Final downstream test accuracy: {test_acc_down*100:.2f}%')\n",
    "    #     print(f'Downstream speed of convergence: {speed_down*100:.2f}%')\n",
    "    #     print()\n",
    "\n",
    "        test_accs_up.append(test_acc_up)\n",
    "        test_accs_down.append(test_acc_down)\n",
    "        speeds_down.append(speed_down)\n",
    "\n",
    "    test_accs_up = np.array(test_accs_up).reshape((2, 3, 3))\n",
    "    test_accs_down = np.array(test_accs_down).reshape((2, 3, 3))\n",
    "    speeds_down = np.array(speeds_down).reshape((2, 3, 3))\n",
    "    metrics = np.multiply(test_accs_up, test_accs_down, speeds_down)\n",
    "\n",
    "    print('Upstream accuracy:')\n",
    "    print(test_accs_up)\n",
    "    print('Downstream accuracy:')\n",
    "    print(test_accs_down)\n",
    "    print('Downstream speed:')\n",
    "    print(speeds_down)\n",
    "    print('Product:')\n",
    "    print(metrics)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Henceforth, we use GD directly on inputs but use plasticity rules in the output and hidden layers.\n",
    "opts = Options(gd_input=True,\n",
    "               use_graph_rule=True,\n",
    "               gd_graph_rule=True,\n",
    "               use_output_rule=True,\n",
    "               gd_output_rule=True,\n",
    "               gd_output=False)\n",
    "scheme = UpdateScheme(cross_entropy_loss=True,\n",
    "                      mse_loss=False,\n",
    "                      update_misclassified_only=False,\n",
    "                      update_all_edges=True)\n",
    "\n",
    "# Feed-forward brain config.\n",
    "n_up = 16  # Input layer size for meta-learning.\n",
    "n_down = 16  # Input layer size for desired task training.\n",
    "n = 16  # Input layer size.\n",
    "m = 2  # Output layer size.\n",
    "p = 0.5  # Connectivity probability.\n",
    "\n",
    "# Training config.\n",
    "num_runs = 5\n",
    "num_rule_epochs = 50\n",
    "num_epochs_upstream = 1\n",
    "num_epochs_downstream = 1\n",
    "dataset = 'halfspace'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 16\n",
      "Cap: 8\n",
      "==== Interpretation: Pre and Post ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:55<00:00,  2.31s/it]\n",
      "  4%|▎         | 54/1500 [00:00<00:02, 496.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3789\n",
      "Last train accuracy: 0.9347\n",
      "Last test accuracy: 0.9120\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4940\n",
      "INITIAL test accuracy: 0.4600\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 429.37it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6304\n",
      "Last train accuracy: 0.6707\n",
      "Last test accuracy: 0.6820\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:49<00:00,  2.18s/it]\n",
      "  2%|▏         | 29/1500 [00:00<00:05, 284.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4887\n",
      "Last test accuracy: 0.4920\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4987\n",
      "INITIAL test accuracy: 0.4860\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 404.29it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4987\n",
      "Last test accuracy: 0.4860\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:48<00:00,  2.18s/it]\n",
      "  3%|▎         | 49/1500 [00:00<00:03, 483.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5093\n",
      "Last test accuracy: 0.5020\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5227\n",
      "INITIAL test accuracy: 0.5360\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 443.10it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5227\n",
      "Last test accuracy: 0.5360\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:52<00:00,  2.25s/it]\n",
      "  0%|          | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3656\n",
      "Last train accuracy: 0.9647\n",
      "Last test accuracy: 0.9380\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5047\n",
      "INITIAL test accuracy: 0.5280\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 415.02it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7123\n",
      "Last train accuracy: 0.5933\n",
      "Last test accuracy: 0.6040\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:56<00:00,  2.34s/it]\n",
      "  3%|▎         | 49/1500 [00:00<00:03, 482.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3676\n",
      "Last train accuracy: 0.9667\n",
      "Last test accuracy: 0.9400\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5020\n",
      "INITIAL test accuracy: 0.4880\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 381.14it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7349\n",
      "Last train accuracy: 0.6007\n",
      "Last test accuracy: 0.5900\n",
      "\n",
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 32\n",
      "Cap: 16\n",
      "==== Interpretation: Pre and Post ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:02<00:00,  2.44s/it]\n",
      "  3%|▎         | 45/1500 [00:00<00:03, 441.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3538\n",
      "Last train accuracy: 0.9693\n",
      "Last test accuracy: 0.9420\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4887\n",
      "INITIAL test accuracy: 0.4800\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:04<00:00, 314.78it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7169\n",
      "Last train accuracy: 0.5813\n",
      "Last test accuracy: 0.5940\n",
      "\n",
      "\n",
      "Run 2 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.42s/it]\n",
      "  3%|▎         | 47/1500 [00:00<00:03, 465.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3564\n",
      "Last train accuracy: 0.9620\n",
      "Last test accuracy: 0.9280\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5007\n",
      "INITIAL test accuracy: 0.4560\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 402.46it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6470\n",
      "Last train accuracy: 0.6533\n",
      "Last test accuracy: 0.6320\n",
      "\n",
      "\n",
      "Run 3 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:59<00:00,  2.38s/it]\n",
      "  3%|▎         | 46/1500 [00:00<00:03, 457.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3570\n",
      "Last train accuracy: 0.9707\n",
      "Last test accuracy: 0.9420\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4780\n",
      "INITIAL test accuracy: 0.5180\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 394.38it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.7069\n",
      "Last train accuracy: 0.6307\n",
      "Last test accuracy: 0.6280\n",
      "\n",
      "\n",
      "Run 4 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.42s/it]\n",
      "  3%|▎         | 47/1500 [00:00<00:03, 464.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4820\n",
      "Last test accuracy: 0.5180\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.5000\n",
      "INITIAL test accuracy: 0.5080\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 391.62it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5000\n",
      "Last test accuracy: 0.5080\n",
      "\n",
      "\n",
      "Run 5 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:55<00:00,  2.31s/it]\n",
      "  3%|▎         | 46/1500 [00:00<00:03, 459.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3597\n",
      "Last train accuracy: 0.9653\n",
      "Last test accuracy: 0.9380\n",
      "Training SAME brain instance (NO backprop)...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.4980\n",
      "INITIAL test accuracy: 0.4720\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:03<00:00, 416.49it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 0.6788\n",
      "Last train accuracy: 0.6500\n",
      "Last test accuracy: 0.6640\n",
      "\n",
      "Universal: False\n",
      "Number hidden layers: 2\n",
      "Hidden layer width: 64\n",
      "Cap: 32\n",
      "==== Interpretation: Pre and Post ====\n",
      "\n",
      "Run 1 / 5...\n",
      "Meta-learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [01:29<00:44,  2.61s/it]"
     ]
    }
   ],
   "source": [
    "hyperparams = []\n",
    "all_stats = []\n",
    "\n",
    "for universal in [False, True]:  # Specialized rules or not?\n",
    "    \n",
    "    for l in [2, 3, 4]:  # Number of hidden layers.\n",
    "        \n",
    "        for w in [16, 32, 64]:  # Width of hidden layers.\n",
    "            \n",
    "            cap = w // 2  # Number of nodes firing per layer.\n",
    "            print('Universal:', universal)\n",
    "            print('Number hidden layers:', l)\n",
    "            print('Hidden layer width:', w)\n",
    "            print('Cap:', cap)\n",
    "            hyperparams.append((universal, l, w, cap))\n",
    "            \n",
    "            brain_prepost_fact = lambda: FFLocalNet(\n",
    "                n, m, l, w, p, cap,\n",
    "                hl_rules=TableRule_PrePost() if universal else [TableRule_PrePost()] * (l-1),\n",
    "                output_rule=TableRule_PrePost(), options=opts, update_scheme=scheme)\n",
    "            \n",
    "            print('==== Interpretation: Pre and Post ====')\n",
    "            cur_stats = evaluate_brain(\n",
    "                brain_prepost_fact, n, dataset=dataset,\n",
    "                num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "            all_stats.append(cur_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_prepost = get_metrics(hyperparams_prepost, all_stats_prepost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three best configs:\n",
    "\n",
    "* Universal, 2 layers, 64 width (metric 0.69)\n",
    "\n",
    "* Non-universal, 4 layers, 32 width (metric 0.66)\n",
    "\n",
    "* Universal, 2 layers, 32 width (metric 0.62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePostCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparams_prepostcount = []\n",
    "all_stats_prepostcount = []\n",
    "\n",
    "for universal in [False, True]:  # Specialized rules or not?\n",
    "    \n",
    "    for l in [2, 3, 4]:  # Number of hidden layers.\n",
    "        \n",
    "        for w in [16, 32, 64]:  # Width of hidden layers.\n",
    "            \n",
    "            cap = w // 2  # Number of nodes firing per layer.\n",
    "            print('Universal:', universal)\n",
    "            print('Number hidden layers:', l)\n",
    "            print('Hidden layer width:', w)\n",
    "            print('Cap:', cap)\n",
    "            hyperparams_prepostcount.append((universal, l, w, cap))\n",
    "            \n",
    "            brain_prepostcount_fact = lambda: FFLocalNet(\n",
    "                n, m, l, w, p, cap,\n",
    "                hl_rules=TableRule_PrePostCount() if universal else [TableRule_PrePostCount()] * (l-1),\n",
    "                output_rule=TableRule_PrePostCount(), options=opts, update_scheme=scheme)\n",
    "            \n",
    "            print('==== Interpretation: PrePostCount ====')\n",
    "            cur_stats = evaluate_brain(\n",
    "                brain_prepostcount_fact, n, dataset=dataset,\n",
    "                num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "            all_stats_prepostcount.append(cur_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_prepostcount = get_metrics(hyperparams_prepostcount, all_stats_prepostcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrePostPercent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_prepostpercent = []\n",
    "all_stats_prepostpercent = []\n",
    "\n",
    "for universal in [False, True]:  # Specialized rules or not?\n",
    "    \n",
    "    for l in [2, 3, 4]:  # Number of hidden layers.\n",
    "        \n",
    "        for w in [16, 32, 64]:  # Width of hidden layers.\n",
    "            \n",
    "            cap = w // 2  # Number of nodes firing per layer.\n",
    "            print('Universal:', universal)\n",
    "            print('Number hidden layers:', l)\n",
    "            print('Hidden layer width:', w)\n",
    "            print('Cap:', cap)\n",
    "            hyperparams_prepostpercent.append((universal, l, w, cap))\n",
    "            \n",
    "            brain_prepostpercent_fact = lambda: FFLocalNet(\n",
    "                n, m, l, w, p, cap,\n",
    "                hl_rules=TableRule_PrePostPercent() if universal else [TableRule_PrePostPercent()] * (l-1),\n",
    "                output_rule=TableRule_PrePostPercent(), options=opts, update_scheme=scheme)\n",
    "            \n",
    "            print('==== Interpretation: PrePostPercent ====')\n",
    "            cur_stats = evaluate_brain(\n",
    "                brain_prepostpercent_fact, n, dataset=dataset,\n",
    "                num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "            all_stats_prepostpercent.append(cur_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_prepostpercent = get_metrics(hyperparams_prepostpercent, all_stats_prepostpercent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
