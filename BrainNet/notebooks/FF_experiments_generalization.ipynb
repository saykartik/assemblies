{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generalization\n",
    "\n",
    "## For every considered model, meta-learn on 16-dimensional halfspace dataset, then transfer rules, and train / test that on MNIST.\n",
    "\n",
    "Created by Basile Van Hoorick, Fall 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FF_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Henceforth, we use GD directly on inputs but use plasticity rules in the output and hidden layers.\n",
    "opts_up = Options(gd_input=True,\n",
    "                  use_graph_rule=True,\n",
    "                  gd_graph_rule=True,\n",
    "                  use_output_rule=True,\n",
    "                  gd_output_rule=True,\n",
    "                  gd_output=False)\n",
    "opts_down = Options(gd_input=True,\n",
    "                    use_graph_rule=True,\n",
    "                    gd_graph_rule=False,  # Not meta-trainable anymore!\n",
    "                    use_output_rule=True,\n",
    "                    gd_output_rule=False,  # Not meta-trainable anymore!\n",
    "                    gd_output=False)\n",
    "scheme = UpdateScheme(cross_entropy_loss=True,\n",
    "                      mse_loss=False,\n",
    "                      update_misclassified_only=False,\n",
    "                      update_all_edges=True)\n",
    "\n",
    "# Feed-forward brain config.\n",
    "n_up = 16  # Input layer size for meta-learning.\n",
    "n_down = 28 * 28  # Input layer size for desired task training.\n",
    "m_up = 2  # Output layer size for meta-learning.\n",
    "m_down = 10  # Output layer size for desired task training.\n",
    "l = 4  # Number of hidden layers.\n",
    "w = 64  # Width of hidden layers.\n",
    "p = 0.5  # Connectivity probability.\n",
    "cap = 32  # Number of nodes firing per layer.\n",
    "\n",
    "# Training config.\n",
    "num_runs = 10\n",
    "num_rule_epochs = 50\n",
    "num_epochs_upstream = 1\n",
    "num_epochs_downstream = 1\n",
    "dataset_up = 'halfspace'\n",
    "dataset_down = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate brain factories.\n",
    "brain_rnn_up_fact = lambda: LocalNet(n_up, m_up, 64, p, 32, 2, options=opts_up, update_scheme=scheme)\n",
    "brain_rnn_down_fact = lambda: LocalNet(n_down, m_down, 640, p, 320, 2, options=opts_down, update_scheme=scheme)\n",
    "\n",
    "brain_prepost_up_fact = lambda: FFLocalNet(\n",
    "    n_up, m_up, l, w, p, cap, hl_rules=TableRule_PrePost(),\n",
    "    output_rule=TableRule_PrePost(), options=opts_up, update_scheme=scheme)\n",
    "brain_prepost_down_fact = lambda: FFLocalNet(\n",
    "    n_down, m_down, l, w*10, p, cap*10, hl_rules=TableRule_PrePost(),\n",
    "    output_rule=TableRule_PrePost(), options=opts_down, update_scheme=scheme)\n",
    "brain_prepostcount_up_fact = lambda: FFLocalNet(\n",
    "    n_up, m_up, l, w, p, cap, hl_rules=TableRule_PrePostCount(),\n",
    "    output_rule=TableRule_PrePostCount(), options=opts_up, update_scheme=scheme)\n",
    "brain_prepostcount_down_fact = lambda: FFLocalNet(\n",
    "    n_down, m_down, l, w*10, p, cap*10, hl_rules=TableRule_PrePostCount(),\n",
    "    output_rule=TableRule_PrePostCount(), options=opts_down, update_scheme=scheme)\n",
    "\n",
    "brain_prepost_nonuni_up_fact = lambda: FFLocalNet(\n",
    "    n_up, m_up, l, w, p, cap, hl_rules=[TableRule_PrePost(), TableRule_PrePost(), TableRule_PrePost()],\n",
    "    output_rule=TableRule_PrePost(), options=opts_up, update_scheme=scheme)\n",
    "brain_prepost_nonuni_down_fact = lambda: FFLocalNet(\n",
    "    n_down, m_down, l, w*10, p, cap*10, hl_rules=[TableRule_PrePost(), TableRule_PrePost(), TableRule_PrePost()],\n",
    "    output_rule=TableRule_PrePost(), options=opts_down, update_scheme=scheme)\n",
    "brain_prepostcount_nonuni_up_fact = lambda: FFLocalNet(\n",
    "    n_up, m_up, l, w, p, cap, hl_rules=[TableRule_PrePostCount(), TableRule_PrePostCount(), TableRule_PrePostCount()],\n",
    "    output_rule=TableRule_PrePostCount(), options=opts_up, update_scheme=scheme)\n",
    "brain_prepostcount_nonuni_down_fact = lambda: FFLocalNet(\n",
    "    n_down, m_down, l, w*10, p, cap*10, hl_rules=[TableRule_PrePostCount(), TableRule_PrePostCount(), TableRule_PrePostCount()],\n",
    "    output_rule=TableRule_PrePostCount(), options=opts_down, update_scheme=scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Original RNN (very different from all the rest) ====\n",
      "\n",
      "Run 1 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:00<00:00,  3.60s/it]\n",
      "../LocalNetBase.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.rnn_rule = torch.tensor(rule).flatten().double()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3458\n",
      "Last train accuracy: 0.9580\n",
      "Last test accuracy: 0.9580\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [32:52<00:00, 30.41it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3612\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 2 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:08<00:00,  3.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3661\n",
      "Last train accuracy: 0.9693\n",
      "Last test accuracy: 0.9580\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0891\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [32:49<00:00, 30.46it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3172\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 3 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:02<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3582\n",
      "Last train accuracy: 0.9447\n",
      "Last test accuracy: 0.9280\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0902\n",
      "INITIAL test accuracy: 0.0891\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [32:43<00:00, 30.56it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3432\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 4 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:50<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3440\n",
      "Last train accuracy: 0.9613\n",
      "Last test accuracy: 0.9400\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0902\n",
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [29:17<00:00, 34.14it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3332\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 5 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:51<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3563\n",
      "Last train accuracy: 0.9460\n",
      "Last test accuracy: 0.9500\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [31:31<00:00, 31.72it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3352\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 6 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:09<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3611\n",
      "Last train accuracy: 0.9480\n",
      "Last test accuracy: 0.9500\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0898\n",
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [33:45<00:00, 29.62it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3532\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 7 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:06<00:00,  3.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3543\n",
      "Last train accuracy: 0.9633\n",
      "Last test accuracy: 0.9420\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0903\n",
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [26:35<00:00, 37.60it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3592\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 8 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:32<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3545\n",
      "Last train accuracy: 0.9507\n",
      "Last test accuracy: 0.9340\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [20:37<00:00, 48.49it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3552\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 9 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:20<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3668\n",
      "Last train accuracy: 0.9507\n",
      "Last test accuracy: 0.9380\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [17:00<00:00, 58.79it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3452\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 10 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3765\n",
      "Last train accuracy: 0.9727\n",
      "Last test accuracy: 0.9660\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [17:09<00:00, 58.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3652\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models.\n",
    "print('==== Original RNN (very different from all the rest) ====')\n",
    "stats_rnn_up, stats_rnn_down = evaluate_generalization(\n",
    "    brain_rnn_up_fact, brain_rnn_down_fact, n_up, n_down,\n",
    "    dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Interpretation: PrePost (universal) ====\n",
      "\n",
      "Run 1 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:24<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4840\n",
      "Last test accuracy: 0.5060\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [24:29<00:00, 40.82it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3026\n",
      "Last train accuracy: 0.0987\n",
      "Last test accuracy: 0.0980\n",
      "\n",
      "\n",
      "Run 2 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:21<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4960\n",
      "Last test accuracy: 0.4660\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [24:57<00:00, 40.06it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3026\n",
      "Last train accuracy: 0.0987\n",
      "Last test accuracy: 0.0980\n",
      "\n",
      "\n",
      "Run 3 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:14<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.3848\n",
      "Last train accuracy: 0.9313\n",
      "Last test accuracy: 0.9380\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [26:01<00:00, 38.42it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.3732\n",
      "Last train accuracy: 0.1124\n",
      "Last test accuracy: 0.1135\n",
      "\n",
      "\n",
      "Run 4 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:24<00:00,  4.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5167\n",
      "Last test accuracy: 0.4580\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [25:56<00:00, 38.56it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.2142\n",
      "Last train accuracy: 0.1927\n",
      "Last test accuracy: 0.1965\n",
      "\n",
      "\n",
      "Run 5 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:34<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.4257\n",
      "Last train accuracy: 0.8647\n",
      "Last test accuracy: 0.8280\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [25:55<00:00, 38.57it/s]  \n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 2.2172\n",
      "Last train accuracy: 0.2613\n",
      "Last test accuracy: 0.2665\n",
      "\n",
      "\n",
      "Run 6 / 10...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:34<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.4967\n",
      "Last test accuracy: 0.5200\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance (WITH backprop) on mnist...\n",
      "INITIAL train accuracy: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL test accuracy: 0.0980\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 51497/60000 [20:42<03:03, 46.46it/s]  "
     ]
    }
   ],
   "source": [
    "print('==== Interpretation: PrePost (universal) ====')\n",
    "stats_prepost_up, stats_prepost_down = evaluate_generalization(\n",
    "    brain_prepost_up_fact, brain_prepost_down_fact, n_up, n_down,\n",
    "    dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "print('==== Interpretation: PrePostCount (universal) ====')\n",
    "stats_prepostcount_up, stats_prepostcount_down = evaluate_generalization(\n",
    "    brain_prepostcount_up_fact, brain_prepostcount_down_fact, n_up, n_down,\n",
    "    dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    print('==== Interpretation: PrePost (NOT universal) ====')\n",
    "    stats_prepost_nonuni_up, stats_prepost_nonuni_down = evaluate_generalization(\n",
    "        brain_prepost_nonuni_up_fact, brain_prepost_nonuni_down_fact, n_up, n_down,\n",
    "        dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "        num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "        num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "    print('==== Interpretation: PrePostCount (NOT universal) ====')\n",
    "    stats_prepostcount_nonuni_up, stats_prepostcount_nonuni_down = evaluate_generalization(\n",
    "        brain_prepostcount_nonuni_up_fact, brain_prepostcount_nonuni_down_fact, n_up, n_down,\n",
    "        dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "        num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "        num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot aggregated stats.\n",
    "agg_stats_rnn_up = convert_multi_stats_uncertainty(stats_rnn_up)\n",
    "agg_stats_rnn_down = convert_multi_stats_uncertainty(stats_rnn_down)\n",
    "plot_curves(agg_stats_rnn_up, agg_stats_rnn_down,\n",
    "            '[RNN] Upstream meta-learning on ' + dataset_up,\n",
    "            '[RNN] Downstream training on ' + dataset_down,\n",
    "            'figs/generalization_rnn_' + dataset_up + '_' + dataset_down,\n",
    "            no_downstream_loss=True)\n",
    "\n",
    "agg_stats_prepost_up = convert_multi_stats_uncertainty(stats_prepost_up)\n",
    "agg_stats_prepost_down = convert_multi_stats_uncertainty(stats_prepost_down)\n",
    "plot_curves(agg_stats_prepost_up, agg_stats_prepost_down,\n",
    "            '[PrePost-Uni] Upstream meta-learning on ' + dataset_up,\n",
    "            '[PrePost-Uni] Downstream training on ' + dataset_down,\n",
    "            'figs/generalization_prepost_uni_' + dataset_up + '_' + dataset_down,\n",
    "            no_downstream_loss=True)\n",
    "agg_stats_prepostcount_up = convert_multi_stats_uncertainty(stats_prepostcount_up)\n",
    "agg_stats_prepostcount_down = convert_multi_stats_uncertainty(stats_prepostcount_down)\n",
    "plot_curves(agg_stats_prepostcount_up, agg_stats_prepostcount_down,\n",
    "            '[PrePostCount-Uni] Upstream meta-learning on ' + dataset_up,\n",
    "            '[PrePostCount-Uni] Downstream training on ' + dataset_down,\n",
    "            'figs/generalization_prepostcount_uni_' + dataset_up + '_' + dataset_down,\n",
    "            no_downstream_loss=True)\n",
    "\n",
    "if 0:\n",
    "    agg_stats_prepost_nonuni_up = convert_multi_stats_uncertainty(stats_prepost_nonuni_up)\n",
    "    agg_stats_prepost_nonuni_down = convert_multi_stats_uncertainty(stats_prepost_nonuni_down)\n",
    "    plot_curves(agg_stats_prepost_nonuni_up, agg_stats_prepost_nonuni_down,\n",
    "                '[PrePost-Uni] Upstream meta-learning on ' + dataset_up,\n",
    "                '[PrePost-Uni] Downstream training on ' + dataset_down,\n",
    "                'figs/generalization_prepost_nonuni_' + dataset_up + '_' + dataset_down,\n",
    "                no_downstream_loss=True)\n",
    "    agg_stats_prepostcount_nonuni_up = convert_multi_stats_uncertainty(stats_prepostcount_nonuni_up)\n",
    "    agg_stats_prepostcount_nonuni_down = convert_multi_stats_uncertainty(stats_prepostcount_nonuni_down)\n",
    "    plot_curves(agg_stats_prepostcount_nonuni_up, agg_stats_prepostcount_nonuni_down,\n",
    "                '[PrePostCount-Uni] Upstream meta-learning on ' + dataset_up,\n",
    "                '[PrePostCount-Uni] Downstream training on ' + dataset_down,\n",
    "                'figs/generalization_prepostcount_nonuni_' + dataset_up + '_' + dataset_down,\n",
    "                no_downstream_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train vanilla net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model.\n",
    "brain_vanilla = FFBrainNet(\n",
    "    n_down, m_down, l, w*10, p, cap*10, full_gd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model.\n",
    "print('==== Vanilla ====')\n",
    "X_train, y_train, X_test, y_test = quick_get_data('mnist', 28 * 28)\n",
    "print('Training VANILLA brain instance (WITH backprop) on mnist...')\n",
    "stats_vanilla = train_downstream(\n",
    "    X_train, y_train, brain_vanilla, num_epochs=num_epochs_downstream,\n",
    "    batch_size=100, vanilla=True, learn_rate=5e-3,\n",
    "    X_test=X_test, y_test=y_test, verbose=False, stats_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot aggregated stats.\n",
    "plot_curves(None, stats_vanilla, None,\n",
    "            '[Vanilla] Downstream training on ' + dataset_down,\n",
    "            'figs/generalization_vanilla_' + dataset_down,\n",
    "            no_downstream_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare some.\n",
    "all_stats_up = [agg_stats_rnn_up, agg_stats_prepost_up, agg_stats_prepostcount_up, None]\n",
    "all_stats_down = [agg_stats_rnn_down, agg_stats_prepost_down, agg_stats_prepostcount_down, stats_vanilla]\n",
    "labels = ['RNN', 'PrePost', 'PrePostCount', 'Vanilla']\n",
    "plot_compare_models(all_stats_up, all_stats_down, labels,\n",
    "                    'Upstream meta-learning on ' + dataset_up,\n",
    "                    'Downstream training on ' + dataset_down,\n",
    "                    'figs/generalization_all_' + dataset_up + '_' + dataset_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to compare all.\n",
    "if 0:\n",
    "    all_stats_up = [agg_stats_rnn_up, agg_stats_prepost_up, agg_stats_prepostcount_up, agg_stats_prepost_nonuni_up, agg_stats_prepostcount_nonuni_up, None]\n",
    "    all_stats_down = [agg_stats_rnn_down, agg_stats_prepost_down, agg_stats_prepostcount_down, agg_stats_prepost_nonuni_down, agg_stats_prepostcount_nonuni_down, stats_vanilla]\n",
    "    labels = ['RNN', 'PrePostUni', 'PrePostCountUni', 'PrePostNonUni', 'PrePostCountNonUni', 'Vanilla']\n",
    "    plot_compare_models(all_stats_up, all_stats_down, labels,\n",
    "                        'Upstream meta-learning on ' + dataset_up,\n",
    "                        'Downstream training on ' + dataset_down,\n",
    "                        'figs/generalization_all_' + dataset_up + '_' + dataset_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
