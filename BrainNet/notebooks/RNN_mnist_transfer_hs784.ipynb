{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to replicate Figure 3\n",
    "\n",
    "Created by Basile Van Hoorick, Fall 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run FF_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Henceforth, we use GD directly on inputs but use plasticity rules in the output and hidden layers.\n",
    "opts_up = Options(gd_input=True,\n",
    "                  use_graph_rule=True,\n",
    "                  gd_graph_rule=True,\n",
    "                  use_output_rule=True,\n",
    "                  gd_output_rule=True,\n",
    "                  gd_output=False)\n",
    "opts_down = Options(gd_input=True,\n",
    "                    use_graph_rule=True,\n",
    "                    gd_graph_rule=False,  # Not meta-trainable anymore!\n",
    "                    use_output_rule=True,\n",
    "                    gd_output_rule=False,  # Not meta-trainable anymore!\n",
    "                    gd_output=False)\n",
    "if 0:\n",
    "    scheme = UpdateScheme(cross_entropy_loss=True,\n",
    "                          mse_loss=False,\n",
    "                          update_misclassified_only=False,  # Deviates from paper.\n",
    "                          update_all_edges=True)  # Deviates from paper.\n",
    "else:\n",
    "    # Same as paper.\n",
    "    scheme = UpdateScheme(cross_entropy_loss=True,\n",
    "                          mse_loss=False,\n",
    "                          update_misclassified_only=True,\n",
    "                          update_all_edges=False)\n",
    "\n",
    "# Feed-forward brain config.\n",
    "n_up = 28 * 28  # Unknown in paper.\n",
    "n_down = 28 * 28\n",
    "m_up = 2  # Unknown in paper.\n",
    "m_down = 10\n",
    "p = 0.5\n",
    "\n",
    "# Training config.\n",
    "num_runs = 1\n",
    "num_rule_epochs = 50\n",
    "num_epochs_upstream = 1\n",
    "num_epochs_downstream = 1\n",
    "dataset_up = 'halfspace'\n",
    "dataset_down = 'mnist'  # T=3 deviates from paper, should be relu, but not enough parameters specified :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook: Transfer rules, correct dimensionality everywhere, !disable! backprop downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate brain factories.\n",
    "# NOTE: Large networks (|V| = 1000) only exist downstream.\n",
    "brain_v100_t1_up_fact = lambda: LocalNet(n_up, m_up, 100, p, 50, 0, options=opts_up, update_scheme=scheme)\n",
    "brain_v100_t3_up_fact = lambda: LocalNet(n_up, m_up, 100, p, 50, 2, options=opts_up, update_scheme=scheme)\n",
    "brain_v100_t1_down_fact = lambda: LocalNet(n_down, m_down, 100, p, 50, 0, options=opts_down, update_scheme=scheme)\n",
    "brain_v100_t3_down_fact = lambda: LocalNet(n_down, m_down, 100, p, 50, 2, options=opts_down, update_scheme=scheme)\n",
    "brain_v1000_t1_down_fact = lambda: LocalNet(n_down, m_down, 1000, p, 500, 0, options=opts_down, update_scheme=scheme)\n",
    "brain_v1000_t3_down_fact = lambda: LocalNet(n_down, m_down, 1000, p, 500, 2, options=opts_down, update_scheme=scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run 1 / 1...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:27<00:00,  5.35s/it]\n",
      "../LocalNetBase.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.rnn_rule = torch.tensor(rule).flatten().double()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6721\n",
      "Last train accuracy: 0.6140\n",
      "Last test accuracy: 0.5840\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance on mnist...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.0903\n",
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [04:57<00:00, 201.87it/s]\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 1.6603\n",
      "Last train accuracy: 0.7717\n",
      "Last test accuracy: 0.7840\n",
      "\n",
      "\n",
      "Run 1 / 1...\n",
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [08:44<00:00, 10.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6510\n",
      "Last train accuracy: 0.5267\n",
      "Last test accuracy: 0.5160\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance on mnist...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.1091\n",
      "INITIAL test accuracy: 0.1105\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [14:54<00:00, 67.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 1.7632\n",
      "Last train accuracy: 0.5144\n",
      "Last test accuracy: 0.5243\n",
      "\n",
      "\n",
      "Run 1 / 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:59<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6540\n",
      "Last train accuracy: 0.6513\n",
      "Last test accuracy: 0.5680\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance on mnist...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.0903\n",
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [17:41<00:00, 56.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last loss: 1.5293\n",
      "Last train accuracy: 0.8526\n",
      "Last test accuracy: 0.8562\n",
      "\n",
      "\n",
      "Run 1 / 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-learning on halfspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [10:22<00:00, 12.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last loss: 0.6931\n",
      "Last train accuracy: 0.5120\n",
      "Last test accuracy: 0.5680\n",
      "mnist_train: 60000\n",
      "mnist_test: 10000\n",
      "Training NEW brain instance on mnist...\n",
      "===> WARNING: Backprop is disabled, which means that all layers without rules will never change their weights!\n",
      "===> This is NOT recommended by Basile!\n",
      "INITIAL train accuracy: 0.0901\n",
      "INITIAL test accuracy: 0.0892\n",
      "Epoch 1 / 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2701/60000 [06:54<2:26:28,  6.52it/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:65] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 8000000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-767b98860b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mn_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_down\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_up\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_down\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_down\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdownstream_backprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rule_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_rule_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-66bff3f9f755>\u001b[0m in \u001b[0;36mevaluate_up_down\u001b[0;34m(brain_up_fact, brain_down_fact, n_up, n_down, dataset_up, dataset_down, downstream_backprop, num_runs, num_rule_epochs, num_epochs_upstream, num_epochs_downstream, get_model)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvanilla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             stats_interval=500, disable_backprop=not(downstream_backprop))\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Save this run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/train.py\u001b[0m in \u001b[0;36mtrain_downstream\u001b[0;34m(X, y, model, num_epochs, batch_size, vanilla, learn_rate, X_test, y_test, verbose, stats_interval, disable_backprop)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0;31m# Update selected weights using rules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinue_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontinue_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;31m# Update remaining weights using backprop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/LocalNetBase.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, labels, epochs, batch, continue_)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/assemblies/BrainNet/LocalNetBase.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, probs, label)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrounds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mact\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:65] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 8000000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "# Evaluate models.\n",
    "print('=====> v100_t1')\n",
    "stats_v100_t1_up, stats_v100_t1_down = evaluate_up_down(\n",
    "    brain_v100_t1_up_fact, brain_v100_t1_down_fact,\n",
    "    n_up, n_down, dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    downstream_backprop=False, num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "print('=====> v100_t3')\n",
    "stats_v100_t3_up, stats_v100_t3_down = evaluate_up_down(\n",
    "    brain_v100_t3_up_fact, brain_v100_t3_down_fact,\n",
    "    n_up, n_down, dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    downstream_backprop=False, num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "print('=====> v1000_t1')\n",
    "stats_v1000_t1_up, stats_v1000_t1_down = evaluate_up_down(\n",
    "    brain_v100_t1_up_fact, brain_v1000_t1_down_fact,\n",
    "    n_up, n_down, dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    downstream_backprop=False, num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)\n",
    "print('=====> v1000_t3')\n",
    "stats_v1000_t3_up, stats_v1000_t3_down = evaluate_up_down(\n",
    "    brain_v100_t3_up_fact, brain_v1000_t3_down_fact,\n",
    "    n_up, n_down, dataset_up=dataset_up, dataset_down=dataset_down,\n",
    "    downstream_backprop=False, num_runs=num_runs, num_rule_epochs=num_rule_epochs,\n",
    "    num_epochs_upstream=num_epochs_upstream, num_epochs_downstream=num_epochs_downstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
