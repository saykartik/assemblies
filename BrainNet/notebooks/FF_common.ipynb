{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful code for sharing across our notebooks.\n",
    "\n",
    "Created by Basile Van Hoorick, Fall 2020.\n",
    "\n",
    "To import, type in the first code cell:\n",
    "\n",
    "%run FF_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports.\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets\n",
    "\n",
    "sys.path.append('../')\n",
    "plt.style.use('seaborn')\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "default_colors = prop_cycle.by_key()['color']  # NOTE: Only six colors.\n",
    "\n",
    "# Repository imports.\n",
    "from DataGenerator import random_halfspace_data, layer_relu_data\n",
    "from FFBrainNet import FFBrainNet\n",
    "from FFLocalNet import FFLocalNet\n",
    "from FFLocalPlasticityRules.TableRule_PrePost import TableRule_PrePost\n",
    "from FFLocalPlasticityRules.TableRule_PrePostCount import TableRule_PrePostCount\n",
    "from FFLocalPlasticityRules.TableRule_PrePostPercent import TableRule_PrePostPercent\n",
    "from FFLocalPlasticityRules.TableRule_PostCount import TableRule_PostCount\n",
    "from FFLocalPlasticityRules.OneBetaANNRule_PrePost import OneBetaANNRule_PrePost\n",
    "from FFLocalPlasticityRules.OneBetaANNRule_PrePostAll import OneBetaANNRule_PrePostAll\n",
    "from FFLocalPlasticityRules.OneBetaANNRule_PostAll import OneBetaANNRule_PostAll\n",
    "from FFLocalPlasticityRules.AllBetasANNRule_PostAll import AllBetasANNRule_PostAll\n",
    "from LocalNetBase import Options, UpdateScheme\n",
    "from network import LocalNet\n",
    "from train import metalearn_rules, train_downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_get_data(which, dim, N=2000, split=0.75, relu_k=8):\n",
    "    '''\n",
    "    Quick, get some data!\n",
    "    '''\n",
    "    which = which.lower()\n",
    "    \n",
    "    if which == 'halfspace':\n",
    "        X, y = random_halfspace_data(dim=dim, n=N)\n",
    "    \n",
    "    elif which == 'relu':\n",
    "        X, y = layer_relu_data(n_up, N*3, relu_k)\n",
    "        print('Count of 0:', np.sum(y == 0), ' Count of 1:', np.sum(y == 1))\n",
    "    \n",
    "    elif which == 'mnist':\n",
    "        # NOTE: Argument N is ignored here.\n",
    "        mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "        mnist_test = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=None)\n",
    "        print('mnist_train:', len(mnist_train))\n",
    "        print('mnist_test:', len(mnist_test))\n",
    "        X_train = np.array([np.array(pair[0]) for pair in mnist_train]) / 255.0\n",
    "        y_train = np.array([pair[1] for pair in mnist_train])\n",
    "        X_test = np.array([np.array(pair[0]) for pair in mnist_test]) / 255.0\n",
    "        y_test = np.array([pair[1] for pair in mnist_test])\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Unknown or unused dataset: ' + which)\n",
    "    \n",
    "    if which != 'mnist':\n",
    "        X_train = X[:int(N*split)]\n",
    "        y_train = y[:int(N*split)]\n",
    "        X_test = X[int(N*split):]\n",
    "        y_test = y[int(N*split):]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_brain(brain_fact, n,\n",
    "                   dataset_up='halfspace', dataset_down='halfspace', downstream_backprop=False,\n",
    "                   num_runs=1, num_rule_epochs=50, num_epochs_upstream=1, num_epochs_downstream=1,\n",
    "                   min_upstream_acc=0.7):\n",
    "    '''\n",
    "    Evaluate a SINGLE network instance by meta-learning and then\n",
    "    training on a reinitialized dataset of the same dimensionality.\n",
    "    \n",
    "    Args:\n",
    "        brain_fact: Calling brain_fact() will create a new instance of the network under test.\n",
    "        dataset_up: Upstream dataset class (halfspace / relu / mnist).\n",
    "        dataset_down: If None, keep the same dataset instance. Otherwise, downstream dataset class.\n",
    "        downstream_backprop: Use backprop for the direct GD layers downstream?\n",
    "            Recommended False if dataset_down is None, since we assume layers\n",
    "            with direct gradient descent to be trained upstream already.\n",
    "        min_upstream_acc: Keep meta-learning until we find a good random initialization with\n",
    "            this final test accuracy.\n",
    "            \n",
    "    Returns:\n",
    "        (multi_stats_up, multi_stats_down).\n",
    "        Both are lists of length num_runs.\n",
    "    '''\n",
    "    multi_stats_up = []\n",
    "    multi_stats_down = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        print()\n",
    "        print(f'Run {run+1} / {num_runs}...')\n",
    "        \n",
    "        # Upstream.\n",
    "        success = False\n",
    "        while not success:\n",
    "            brain = brain_fact()  # NOTE: Some initializations are unlucky.\n",
    "\n",
    "            X_train, y_train, X_test, y_test = quick_get_data(dataset_up, n)\n",
    "            print('Meta-learning on ' + dataset_up + '...')\n",
    "            stats_up = metalearn_rules(\n",
    "                X_train, y_train, brain, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs=num_epochs_upstream, batch_size=100, learn_rate=1e-2,\n",
    "                X_test=X_test, y_test=y_test, verbose=False)\n",
    "            \n",
    "            success = (stats_up[2][-1] >= min_upstream_acc)\n",
    "            if not success:\n",
    "                print(f'Final upstream test acc {stats_up[2][-1]:.4f} not high enough, retrying...')\n",
    "        \n",
    "        # Downstream.\n",
    "        # NO rule transfer needed since we reuse the same network,\n",
    "        # but just on a possibly altered dataset.\n",
    "        if dataset_down is not None:\n",
    "            X_train, y_train, X_test, y_test = quick_get_data(dataset_down, n)\n",
    "            print('Training SAME brain instance on ' + dataset_down + '...')\n",
    "        else:\n",
    "            print('Training SAME brain instance on the same dataset instance...')\n",
    "        stats_down = train_downstream(\n",
    "            X_train, y_train, brain, num_epochs=num_epochs_downstream,\n",
    "            batch_size=100, vanilla=False, learn_rate=5e-3,\n",
    "            X_test=X_test, y_test=y_test, verbose=False,\n",
    "            stats_interval=500, disable_backprop=not(downstream_backprop))\n",
    "        \n",
    "        # Save this run.\n",
    "        multi_stats_up.append(stats_up)\n",
    "        multi_stats_down.append(stats_down)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return (multi_stats_up, multi_stats_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_up_down(brain_up_fact, brain_down_fact, n_up, n_down,\n",
    "                     dataset_up='halfspace', dataset_down='halfspace', downstream_backprop=False,\n",
    "                     num_runs=1, num_rule_epochs=50, num_epochs_upstream=1, num_epochs_downstream=1,\n",
    "                     get_model=False, min_upstream_acc=0.7):\n",
    "    '''\n",
    "    Evaluates a PAIR of brains on the quality of meta-learning\n",
    "    and rule interpretations by training with transferred rules.\n",
    "    \n",
    "    Args:\n",
    "        brain_up_fact: Calling this will create a new instance of the network to meta-learn.\n",
    "        brain_down_fact: Calling this will create a new instance of the network to train.\n",
    "        dataset_up: Upstream dataset class (halfspace / relu / mnist).\n",
    "        dataset_down: If None, keep the same dataset instance. Otherwise, downstream dataset class.\n",
    "        downstream_backprop: Use backprop for the direct GD layers downstream?\n",
    "            Recommended True, since the downstream weights will remain randomly initialized otherwise.\n",
    "        min_upstream_acc: Keep meta-learning until we find a good random initialization with\n",
    "            this final test accuracy.\n",
    "            \n",
    "    Returns:\n",
    "        (multi_stats_up, multi_stats_down) or ((multi_stats_up, multi_stats_down), brain_down).\n",
    "        Both are lists of length num_runs.\n",
    "    '''\n",
    "    if (dataset_down is None) != (n_down is None):\n",
    "        raise ValueError('The nullness of dataset_down does not agree with that of n_down.')\n",
    "    \n",
    "    multi_stats_up = []\n",
    "    multi_stats_down = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        print()\n",
    "        print(f'Run {run+1} / {num_runs}...')\n",
    "        \n",
    "        # Upstream.\n",
    "        success = False\n",
    "        while not success:\n",
    "            brain_up = brain_up_fact()  # NOTE: Some initializations are unlucky.\n",
    "    \n",
    "            X_train, y_train, X_test, y_test = quick_get_data(dataset_up, n_up)\n",
    "            print('Meta-learning on ' + dataset_up + '...')\n",
    "            stats_up = metalearn_rules(\n",
    "                X_train, y_train, brain_up, num_rule_epochs=num_rule_epochs,\n",
    "                num_epochs=num_epochs_upstream, batch_size=100, learn_rate=1e-2,\n",
    "                X_test=X_test, y_test=y_test, verbose=False)\n",
    "            \n",
    "            success = (stats_up[2][-1] >= min_upstream_acc)\n",
    "            if not success:\n",
    "                print(f'Final upstream test acc {stats_up[2][-1]:.4f} not high enough, retrying...')\n",
    "\n",
    "        # Transfer rules.\n",
    "        brain_down = brain_down_fact()\n",
    "        if isinstance(brain_down, FFLocalNet):\n",
    "            # FF-ANN.\n",
    "            brain_down.copy_rules(brain_up)\n",
    "        else:\n",
    "            # RNN.\n",
    "            try:\n",
    "                if brain_down.options.use_graph_rule:\n",
    "                    brain_down.set_rnn_rule(brain_up.get_rnn_rule())\n",
    "                if brain_down.options.use_output_rule:\n",
    "                    brain_down.set_output_rule(brain_up.get_output_rule())\n",
    "            except:\n",
    "                print('FALLBACK: direct assignment of rules...')\n",
    "                if downstream_backprop:\n",
    "                    print('=> WARNING: Rules might still be updated by GD this way')\n",
    "                brain_down.rnn_rule = brain_up.rnn_rule\n",
    "                brain_down.output_rule = brain_up.output_rule\n",
    "\n",
    "        # Downstream.\n",
    "        if dataset_down is not None and n_down is not None:\n",
    "            X_train, y_train, X_test, y_test = quick_get_data(dataset_down, n_down)\n",
    "            print('Training NEW brain instance on ' + dataset_down + '...')\n",
    "        else:\n",
    "            print('Training NEW brain instance on the same dataset instance...')\n",
    "        stats_down = train_downstream(\n",
    "            X_train, y_train, brain_down, num_epochs=num_epochs_downstream,\n",
    "            batch_size=100, vanilla=False, learn_rate=1e-2,\n",
    "            X_test=X_test, y_test=y_test, verbose=False,\n",
    "            stats_interval=300, disable_backprop=not(downstream_backprop))\n",
    "        \n",
    "        # Save this run.\n",
    "        multi_stats_up.append(stats_up)\n",
    "        multi_stats_down.append(stats_down)\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    \n",
    "    if get_model:\n",
    "        return (multi_stats_up, multi_stats_down), brain_down\n",
    "    else:\n",
    "        return (multi_stats_up, multi_stats_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generalization(brain_up_fact, brain_down_fact, n_up, n_down, **kwargs):\n",
    "    '''\n",
    "    Legacy method.\n",
    "    Evaluate the quality of meta-learning and rule interpretations by\n",
    "    training a different network on a more complex dataset with transferred rules.\n",
    "    '''\n",
    "    kwargs['downstream_backprop'] = True\n",
    "    return evaluate_up_down(brain_up_fact, brain_down_fact, n_up, n_down, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_multi_stats_uncertainty(multi_stats):\n",
    "    '''\n",
    "    Merge and summarize stats from multiple runs into one tuple that\n",
    "    tracks means and standard deviations over time.\n",
    "    '''\n",
    "    all_losses = np.array([s[0] for s in multi_stats])\n",
    "    all_train_acc = np.array([s[1] for s in multi_stats])\n",
    "    all_test_acc = np.array([s[2] for s in multi_stats])\n",
    "#     print('all_losses:', all_losses.shape)\n",
    "    \n",
    "    # Summarize by calculating things across the 'run' dimension.\n",
    "    losses_mean = all_losses.mean(axis=0)\n",
    "    train_acc_mean = all_train_acc.mean(axis=0)\n",
    "    test_acc_mean = all_test_acc.mean(axis=0)\n",
    "    losses_std = all_losses.std(axis=0)\n",
    "    train_acc_std = all_train_acc.std(axis=0)\n",
    "    test_acc_std = all_test_acc.std(axis=0)\n",
    "#     print('losses_mean:', losses_mean.shape)\n",
    "#     print('losses_std:', losses_std.shape)\n",
    "    \n",
    "    sample_counts = multi_stats[0][3]  # We assume that this is the same everywhere!\n",
    "    other_stats = None  # Can't be arsed to combine this.\n",
    "    \n",
    "    agg_stats = (losses_mean, losses_std, train_acc_mean, train_acc_std,\n",
    "                 test_acc_mean, test_acc_std, sample_counts, other_stats)\n",
    "    return agg_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(agg_stats_up, agg_stats_down, title_up, title_down, save_name='figs/default', no_downstream_loss=False):\n",
    "    '''\n",
    "    Plot upstream (optional) and downstream (required) learning curves of ONE model.\n",
    "    If multiple runs were executed, the shaded areas indicate standard deviations.\n",
    "    '''\n",
    "    if len(agg_stats_down) == 5:\n",
    "        # One run.\n",
    "        if agg_stats_up is not None:\n",
    "            (meta_losses, meta_train_acc, meta_test_acc, meta_sample_counts, meta_stats) = agg_stats_up\n",
    "        (plas_losses, plas_train_acc, plas_test_acc, plas_sample_counts, plas_stats) = agg_stats_down\n",
    "        plot_std = False\n",
    "    \n",
    "    else:\n",
    "        # Multiple runs.\n",
    "        if agg_stats_up is not None:\n",
    "            (meta_losses, meta_losses_std, meta_train_acc, meta_train_acc_std,\n",
    "             meta_test_acc, meta_test_acc_std, meta_sample_counts, meta_stats) = agg_stats_up\n",
    "        (plas_losses, plas_losses_std, plas_train_acc, plas_train_acc_std,\n",
    "         plas_test_acc, plas_test_acc_std, plas_sample_counts, plas_stats) = agg_stats_down\n",
    "        plot_std = True\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    # Left plot = upstream.\n",
    "    if agg_stats_up is not None:\n",
    "        ax[0].plot(meta_sample_counts, meta_losses, label='loss', color=default_colors[2])\n",
    "        ax[0].plot(meta_sample_counts, meta_train_acc, label='train', color=default_colors[1])\n",
    "        ax[0].plot(meta_sample_counts, meta_test_acc, label='test', color=default_colors[0])\n",
    "        if plot_std:\n",
    "            ax[0].fill_between(meta_sample_counts, meta_losses - meta_losses_std,\n",
    "                               meta_losses + meta_losses_std, alpha=0.3, facecolor=default_colors[2])\n",
    "            ax[0].fill_between(meta_sample_counts, meta_train_acc - meta_train_acc_std,\n",
    "                               meta_train_acc + meta_train_acc_std, alpha=0.3, facecolor=default_colors[1])\n",
    "            ax[0].fill_between(meta_sample_counts, meta_test_acc - meta_test_acc_std,\n",
    "                               meta_test_acc + meta_test_acc_std, alpha=0.3, facecolor=default_colors[0])\n",
    "        ax[0].set_xlabel('Cumulative number of training samples')\n",
    "        ax[0].set_ylabel('Accuracy / Loss')\n",
    "        ax[0].set_xlim(0, meta_sample_counts[-1])\n",
    "        ax[0].set_title(title_up)\n",
    "        ax[0].legend()\n",
    "    else:\n",
    "        ax[0].set_visible(False)\n",
    "    \n",
    "    # Right plot = downstream.\n",
    "    if not no_downstream_loss:\n",
    "        ax[1].plot(plas_sample_counts[1:], plas_losses[1:], label='loss', color=default_colors[2])\n",
    "    ax[1].plot(plas_sample_counts, plas_train_acc, label='train', color=default_colors[1])\n",
    "    ax[1].plot(plas_sample_counts, plas_test_acc, label='test', color=default_colors[0])\n",
    "    if plot_std:\n",
    "        if not no_downstream_loss:\n",
    "            ax[1].fill_between(plas_sample_counts[1:], plas_losses[1:] - plas_losses_std[1:],\n",
    "                               plas_losses[1:] + plas_losses_std[1:], alpha=0.3, facecolor=default_colors[2])\n",
    "        ax[1].fill_between(plas_sample_counts, plas_train_acc - plas_train_acc_std,\n",
    "                           plas_train_acc + plas_train_acc_std, alpha=0.3, facecolor=default_colors[1])\n",
    "        ax[1].fill_between(plas_sample_counts, plas_test_acc - plas_test_acc_std,\n",
    "                           plas_test_acc + plas_test_acc_std, alpha=0.3, facecolor=default_colors[0])\n",
    "    ax[1].set_xlabel('Cumulative number of training samples')\n",
    "    ax[1].set_ylabel('Accuracy / Loss')\n",
    "    ax[1].set_xlim(0, plas_sample_counts[-1])\n",
    "    ax[1].set_title(title_down)\n",
    "    ax[1].legend()\n",
    "    \n",
    "    # Store and display graph.\n",
    "    print('Saving figure to:', save_name)\n",
    "    plt.savefig(save_name + '.pdf', dpi=192)\n",
    "    plt.savefig(save_name + '.png', dpi=192)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print essential stats.\n",
    "    print('Mean essential stats across all runs:')\n",
    "    if agg_stats_up is not None:\n",
    "        print(f'Last upstream loss: {meta_losses[-1]:.4f}')\n",
    "        print(f'Last upstream train accuracy: {meta_train_acc[-1]:.4f}')\n",
    "        print(f'Last upstream test accuracy: {meta_test_acc[-1]:.4f}')\n",
    "    print(f'Last downstream loss: {plas_losses[-1]:.4f}')\n",
    "    print(f'Last downstream train accuracy: {plas_train_acc[-1]:.4f}')\n",
    "    print(f'Last downstream test accuracy: {plas_test_acc[-1]:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_styles(labels):\n",
    "    # NOTE: Please feel free to modify this method to improve your figures.\n",
    "    \n",
    "    colors = copy.deepcopy(default_colors)\n",
    "    styles = ['solid'] * len(labels)\n",
    "    \n",
    "    # Handle exceptions.\n",
    "#     if len(labels) == 8:\n",
    "#         colors = [default_colors[0]] * len(labels)\n",
    "#         colors[0] = default_colors[0]  # RNN\n",
    "#         colors[1] = colors[2] = colors[3] = default_colors[1]  # PrePost\n",
    "#         colors[4] = colors[5] = colors[6] = default_colors[2]  # PrePostCount\n",
    "#         colors[7] = default_colors[3]  # Vanilla\n",
    "#         styles[2] = styles[5] = 'dashed'\n",
    "#         styles[3] = styles[6] = 'dotted'\n",
    "        \n",
    "    return colors, styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_models(all_stats_up, all_stats_down, labels, title_up, title_down, save_name='figs/default'):\n",
    "    '''\n",
    "    Plot upstream (optional) and downstream (required) curves of\n",
    "    only one metric (test accuracy) across MANY models.\n",
    "    '''\n",
    "    num_models = len(all_stats_up)\n",
    "    assert(num_models == len(all_stats_down) and num_models == len(labels))\n",
    "    \n",
    "    if len(labels) > 6:\n",
    "        raise ValueError(\"Too many plots at once (we don't have that many colors)\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    colors, styles = get_colors_styles(labels)\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        agg_stats_up = all_stats_up[i]\n",
    "        agg_stats_down = all_stats_down[i]\n",
    "        \n",
    "        if len(agg_stats_down) == 5:\n",
    "            # One run.\n",
    "            if agg_stats_up is not None:\n",
    "                (meta_losses, meta_train_acc, meta_test_acc, meta_sample_counts, meta_stats) = agg_stats_up\n",
    "            (plas_losses, plas_train_acc, plas_test_acc, plas_sample_counts, plas_stats) = agg_stats_down\n",
    "            plot_std = False\n",
    "        \n",
    "        else:\n",
    "            # Multiple runs.\n",
    "            if agg_stats_up is not None:\n",
    "                (meta_losses, meta_losses_std, meta_train_acc, meta_train_acc_std,\n",
    "                 meta_test_acc, meta_test_acc_std, meta_sample_counts, meta_stats) = agg_stats_up\n",
    "            (plas_losses, plas_losses_std, plas_train_acc, plas_train_acc_std,\n",
    "             plas_test_acc, plas_test_acc_std, plas_sample_counts, plas_stats) = agg_stats_down\n",
    "            plot_std = True\n",
    "        \n",
    "        if agg_stats_up is not None:\n",
    "            ax[0].plot(meta_sample_counts, meta_test_acc, label=labels[i], color=colors[i], linestyle=styles[i])\n",
    "        ax[1].plot(plas_sample_counts, plas_test_acc, label=labels[i], color=colors[i], linestyle=styles[i])\n",
    "        if plot_std:\n",
    "            if agg_stats_up is not None:\n",
    "                ax[0].fill_between(meta_sample_counts, meta_test_acc - meta_test_acc_std,\n",
    "                                   meta_test_acc + meta_test_acc_std, alpha=0.3, facecolor=colors[i], linestyle=styles[i])\n",
    "            ax[1].fill_between(plas_sample_counts, plas_test_acc - plas_test_acc_std,\n",
    "                               plas_test_acc + plas_test_acc_std, alpha=0.3, facecolor=colors[i], linestyle=styles[i])\n",
    "        \n",
    "    ax[0].set_xlabel('Cumulative number of training samples')\n",
    "    ax[0].set_ylabel('Test accuracy')\n",
    "    ax[0].set_title(title_up)\n",
    "    ax[0].legend()\n",
    "    ax[1].set_xlabel('Cumulative number of training samples')\n",
    "    ax[1].set_ylabel('Test accuracy')\n",
    "    ax[1].set_title(title_down)\n",
    "    ax[1].legend()\n",
    "    \n",
    "    # Store and display graph.\n",
    "    print('Saving figure to:', save_name)\n",
    "    plt.savefig(save_name + '.pdf', dpi=192)\n",
    "    plt.savefig(save_name + '.png', dpi=192)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
